{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.util import filter_spans\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT02105766</td>\n",
       "      <td>8:16:chronic_disease,20:32:treatment</td>\n",
       "      <td>portal fibrosis by liver biopsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT03008070</td>\n",
       "      <td>22:34:treatment</td>\n",
       "      <td>Contra-indication to liver biopsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT03008070</td>\n",
       "      <td>,32:44:treatment,,</td>\n",
       "      <td>Have a stable weight since the liver biopsy wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT03008070</td>\n",
       "      <td>26:38:treatment,</td>\n",
       "      <td>Subject agrees to have a liver biopsy performe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT02515708</td>\n",
       "      <td>,43:55:treatment,</td>\n",
       "      <td>Liver steatosis (on visual estimate or on live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>NCT00147056</td>\n",
       "      <td>46:63:cancer,73:80:treatment,82:91:treatment,9...</td>\n",
       "      <td>Subjects with (newly diagnosed or recurrent) m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7352</th>\n",
       "      <td>NCT00107289</td>\n",
       "      <td>1:5:treatment,11:13:cancer,39:48:treatment</td>\n",
       "      <td>MIBG-avid NB and evaluable disease on MIBG sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>NCT00107289</td>\n",
       "      <td>27:29:cancer,157:171:cancer,186:208:chronic_di...</td>\n",
       "      <td>ust have the diagnosis of NB in accordance wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7354</th>\n",
       "      <td>NCT00075387</td>\n",
       "      <td>40:51:treatment,53:69:treatment,71:90:treatmen...</td>\n",
       "      <td>Subjects who have contraindications to carbopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7355</th>\n",
       "      <td>NCT00001337</td>\n",
       "      <td>23:45:chronic_disease,47:68:chronic_disease,72...</td>\n",
       "      <td>No active symptomatic ischemic heart disease, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7356 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID                                               tags  \\\n",
       "0     NCT02105766               8:16:chronic_disease,20:32:treatment   \n",
       "1     NCT03008070                                    22:34:treatment   \n",
       "2     NCT03008070                                 ,32:44:treatment,,   \n",
       "3     NCT03008070                                   26:38:treatment,   \n",
       "4     NCT02515708                                  ,43:55:treatment,   \n",
       "...           ...                                                ...   \n",
       "7351  NCT00147056  46:63:cancer,73:80:treatment,82:91:treatment,9...   \n",
       "7352  NCT00107289         1:5:treatment,11:13:cancer,39:48:treatment   \n",
       "7353  NCT00107289  27:29:cancer,157:171:cancer,186:208:chronic_di...   \n",
       "7354  NCT00075387  40:51:treatment,53:69:treatment,71:90:treatmen...   \n",
       "7355  NCT00001337  23:45:chronic_disease,47:68:chronic_disease,72...   \n",
       "\n",
       "                                                   text  \n",
       "0                       portal fibrosis by liver biopsy  \n",
       "1                     Contra-indication to liver biopsy  \n",
       "2     Have a stable weight since the liver biopsy wa...  \n",
       "3     Subject agrees to have a liver biopsy performe...  \n",
       "4     Liver steatosis (on visual estimate or on live...  \n",
       "...                                                 ...  \n",
       "7351  Subjects with (newly diagnosed or recurrent) m...  \n",
       "7352  MIBG-avid NB and evaluable disease on MIBG sca...  \n",
       "7353  ust have the diagnosis of NB in accordance wit...  \n",
       "7354  Subjects who have contraindications to carbopl...  \n",
       "7355  No active symptomatic ischemic heart disease, ...  \n",
       "\n",
       "[7356 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = pd.read_excel('../data_source/G1.xlsx')\n",
    "d1 = d1.drop(columns=['Unnamed: 0'])\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7356 entries, 0 to 7355\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      7356 non-null   object\n",
      " 1   tags    7356 non-null   object\n",
      " 2   text    7356 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 172.5+ KB\n"
     ]
    }
   ],
   "source": [
    "d1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = d1[~d1.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = d1['tags'].tolist()\n",
    "# text = d1['text'].tolist()\n",
    "# tags = [[y for y in x.split(',') if len(y)!=0] for x in tags]\n",
    "\n",
    "# # tags\n",
    "# print(len(tags), len(text))\n",
    "# idx_to_remove = []\n",
    "# for i, x in enumerate(tags):\n",
    "#     mx_idx = -1\n",
    "#     for y in x:\n",
    "#         start_idx = int(y.split(':')[0])\n",
    "#         end_idx = int(y.split(':')[1])\n",
    "#         mx_idx = max(mx_idx, start_idx, end_idx)\n",
    "\n",
    "#         if(start_idx>end_idx):\n",
    "#             print(y.split(':'))\n",
    "#             print(i,x,\"====\", start_idx, end_idx)\n",
    "#             idx_to_remove.append(i)\n",
    "        \n",
    "#         if(mx_idx > len(text[i])+1):\n",
    "#             print(i, x, text[i])\n",
    "#             idx_to_remove.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxs_to_remove(tags_list, text_list):\n",
    "    idx_to_remove = []\n",
    "\n",
    "    for i, x in enumerate(tags_list):\n",
    "        mx_idx = -1\n",
    "        for y in x:\n",
    "            start_idx = int(y.split(':')[0])\n",
    "            end_idx = int(y.split(':')[1])\n",
    "            mx_idx = max(mx_idx, start_idx, end_idx)\n",
    "\n",
    "            if(start_idx>end_idx):\n",
    "                # print(y.split(':'))\n",
    "                # print(i,x,\"====\", start_idx, end_idx)\n",
    "                idx_to_remove.append(i)\n",
    "            \n",
    "            if(mx_idx > len(text_list[i])+1):\n",
    "                # print(i, x, text_list[i])\n",
    "                idx_to_remove.append(i)\n",
    "\n",
    "    return idx_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7356 entries, 0 to 7355\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      7356 non-null   object\n",
      " 1   tags    7356 non-null   object\n",
      " 2   text    7356 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 172.5+ KB\n",
      "None \n",
      "\n",
      "No. of duplicates in dataframe - 167\n",
      "Unique labels in tags columns: {'chronic_disease', 'cancer', 'treatment', 'allergy_name'} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def quick_eda(df):\n",
    "    print(df.info(), \"\\n\")\n",
    "    print(\"No. of duplicates in dataframe - {}\".format(df.loc[df.duplicated()].shape[0]))\n",
    "    \n",
    "    tags = df['tags'].tolist()\n",
    "    text = df['text'].tolist()\n",
    "    tags = [[y for y in x.split(',') if len(y)!=0] for x in tags]\n",
    "    set_labels = set([y.split(':')[-1] for x in tags for y in x])\n",
    "    print(\"Unique labels in tags columns: {}\".format(set_labels),\"\\n\\n\")\n",
    "\n",
    "    return \n",
    "\n",
    "quick_eda(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entites(tags, text):\n",
    "    entities = []\n",
    "    for x in tags:\n",
    "        temp = []\n",
    "        for y in x:\n",
    "            temp_ls = y.split(':')\n",
    "            start_idx = int(temp_ls[0])\n",
    "            end_idx = int(temp_ls[1])\n",
    "            label = temp_ls[-1]\n",
    "            tup = (start_idx, end_idx, label)\n",
    "            # print(tup)\n",
    "            temp.append(tup)\n",
    "        entities.append(temp)\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    print('original_shape: {}'.format(df.shape))\n",
    "    df = df.drop_duplicates()\n",
    "    print('shape after duplicates drop: {}'.format(df.shape))\n",
    "    tags = df['tags'].tolist()\n",
    "    text = df['text'].tolist()\n",
    "    tags = [[y for y in x.split(',') if len(y)!=0] for x in tags]\n",
    "    # print(tags[:5])\n",
    "    entities = create_entites(tags=tags, text=text)\n",
    "    df['entities'] = entities\n",
    "    remove_idx_ls = idxs_to_remove(tags, text)\n",
    "    print(\"{} indices to remove\".format(len(remove_idx_ls)))\n",
    "    print('Removing_index: {}'.format(remove_idx_ls))\n",
    "    df = df.drop(remove_idx_ls, axis=0).reset_index()\n",
    "\n",
    "    print(\"Final columns: {}\".format(df.columns))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_shape: (7356, 3)\n",
      "shape after duplicates drop: (7189, 3)\n",
      "2 indices to remove\n",
      "Removing_index: [1522, 4236]\n",
      "Final columns: Index(['index', 'ID', 'tags', 'text', 'entities'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7187, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = preprocess(d1)\n",
    "\n",
    "d1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_source/G1.xlsx \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7356 entries, 0 to 7355\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      7356 non-null   object\n",
      " 1   tags    7356 non-null   object\n",
      " 2   text    7356 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 172.5+ KB\n",
      "None \n",
      "\n",
      "No. of duplicates in dataframe - 167\n",
      "Unique labels in tags columns: {'chronic_disease', 'cancer', 'treatment', 'allergy_name'} \n",
      "\n",
      "\n",
      "original_shape: (7356, 3)\n",
      "shape after duplicates drop: (7189, 3)\n",
      "2 indices to remove\n",
      "Removing_index: [1522, 4236]\n",
      "Final columns: Index(['index', 'ID', 'tags', 'text', 'entities'], dtype='object')\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "../data_source/G3.xlsx \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6277 entries, 0 to 6276\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      6277 non-null   object\n",
      " 1   tags    6277 non-null   object\n",
      " 2   text    6277 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 147.2+ KB\n",
      "None \n",
      "\n",
      "No. of duplicates in dataframe - 0\n",
      "Unique labels in tags columns: {'chronic_disease', 'cancer', 'treatment', 'allergy_name'} \n",
      "\n",
      "\n",
      "original_shape: (6277, 3)\n",
      "shape after duplicates drop: (6277, 3)\n",
      "0 indices to remove\n",
      "Removing_index: []\n",
      "Final columns: Index(['index', 'ID', 'tags', 'text', 'entities'], dtype='object')\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "../data_source/G2.xlsx \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6454 entries, 0 to 6454\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      6454 non-null   object\n",
      " 1   tags    6454 non-null   object\n",
      " 2   text    6454 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 201.7+ KB\n",
      "None \n",
      "\n",
      "No. of duplicates in dataframe - 0\n",
      "Unique labels in tags columns: {'chronic_disease', 'cancer', 'treatment', 'allergy_name'} \n",
      "\n",
      "\n",
      "original_shape: (6454, 3)\n",
      "shape after duplicates drop: (6454, 3)\n",
      "2 indices to remove\n",
      "Removing_index: [3336, 3472]\n",
      "Final columns: Index(['index', 'ID', 'tags', 'text', 'entities'], dtype='object')\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for f in glob('../data_source/*.xlsx'):\n",
    "    print(f,\"\\n\")\n",
    "    df = pd.read_excel(f)\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    df = df.dropna(axis=0)\n",
    "    quick_eda(df)\n",
    "    df = preprocess(df)\n",
    "\n",
    "    dfs.append(df)\n",
    "    print(\"\\n\\n-------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2, df3 = dfs[0], dfs[1], dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NCT02105766</td>\n",
       "      <td>8:16:chronic_disease,20:32:treatment</td>\n",
       "      <td>portal fibrosis by liver biopsy</td>\n",
       "      <td>[(8, 16, chronic_disease), (20, 32, treatment)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT03008070</td>\n",
       "      <td>22:34:treatment</td>\n",
       "      <td>Contra-indication to liver biopsy</td>\n",
       "      <td>[(22, 34, treatment)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NCT03008070</td>\n",
       "      <td>,32:44:treatment,,</td>\n",
       "      <td>Have a stable weight since the liver biopsy wa...</td>\n",
       "      <td>[(32, 44, treatment)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NCT03008070</td>\n",
       "      <td>26:38:treatment,</td>\n",
       "      <td>Subject agrees to have a liver biopsy performe...</td>\n",
       "      <td>[(26, 38, treatment)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NCT02515708</td>\n",
       "      <td>,43:55:treatment,</td>\n",
       "      <td>Liver steatosis (on visual estimate or on live...</td>\n",
       "      <td>[(43, 55, treatment)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182</th>\n",
       "      <td>7351</td>\n",
       "      <td>NCT00147056</td>\n",
       "      <td>46:63:cancer,73:80:treatment,82:91:treatment,9...</td>\n",
       "      <td>Subjects with (newly diagnosed or recurrent) m...</td>\n",
       "      <td>[(46, 63, cancer), (73, 80, treatment), (82, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>7352</td>\n",
       "      <td>NCT00107289</td>\n",
       "      <td>1:5:treatment,11:13:cancer,39:48:treatment</td>\n",
       "      <td>MIBG-avid NB and evaluable disease on MIBG sca...</td>\n",
       "      <td>[(1, 5, treatment), (11, 13, cancer), (39, 48,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>7353</td>\n",
       "      <td>NCT00107289</td>\n",
       "      <td>27:29:cancer,157:171:cancer,186:208:chronic_di...</td>\n",
       "      <td>ust have the diagnosis of NB in accordance wit...</td>\n",
       "      <td>[(27, 29, cancer), (157, 171, cancer), (186, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>7354</td>\n",
       "      <td>NCT00075387</td>\n",
       "      <td>40:51:treatment,53:69:treatment,71:90:treatmen...</td>\n",
       "      <td>Subjects who have contraindications to carbopl...</td>\n",
       "      <td>[(40, 51, treatment), (53, 69, treatment), (71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>7355</td>\n",
       "      <td>NCT00001337</td>\n",
       "      <td>23:45:chronic_disease,47:68:chronic_disease,72...</td>\n",
       "      <td>No active symptomatic ischemic heart disease, ...</td>\n",
       "      <td>[(23, 45, chronic_disease), (47, 68, chronic_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7187 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index           ID                                               tags  \\\n",
       "0         0  NCT02105766               8:16:chronic_disease,20:32:treatment   \n",
       "1         1  NCT03008070                                    22:34:treatment   \n",
       "2         2  NCT03008070                                 ,32:44:treatment,,   \n",
       "3         3  NCT03008070                                   26:38:treatment,   \n",
       "4         4  NCT02515708                                  ,43:55:treatment,   \n",
       "...     ...          ...                                                ...   \n",
       "7182   7351  NCT00147056  46:63:cancer,73:80:treatment,82:91:treatment,9...   \n",
       "7183   7352  NCT00107289         1:5:treatment,11:13:cancer,39:48:treatment   \n",
       "7184   7353  NCT00107289  27:29:cancer,157:171:cancer,186:208:chronic_di...   \n",
       "7185   7354  NCT00075387  40:51:treatment,53:69:treatment,71:90:treatmen...   \n",
       "7186   7355  NCT00001337  23:45:chronic_disease,47:68:chronic_disease,72...   \n",
       "\n",
       "                                                   text  \\\n",
       "0                       portal fibrosis by liver biopsy   \n",
       "1                     Contra-indication to liver biopsy   \n",
       "2     Have a stable weight since the liver biopsy wa...   \n",
       "3     Subject agrees to have a liver biopsy performe...   \n",
       "4     Liver steatosis (on visual estimate or on live...   \n",
       "...                                                 ...   \n",
       "7182  Subjects with (newly diagnosed or recurrent) m...   \n",
       "7183  MIBG-avid NB and evaluable disease on MIBG sca...   \n",
       "7184  ust have the diagnosis of NB in accordance wit...   \n",
       "7185  Subjects who have contraindications to carbopl...   \n",
       "7186  No active symptomatic ischemic heart disease, ...   \n",
       "\n",
       "                                               entities  \n",
       "0       [(8, 16, chronic_disease), (20, 32, treatment)]  \n",
       "1                                 [(22, 34, treatment)]  \n",
       "2                                 [(32, 44, treatment)]  \n",
       "3                                 [(26, 38, treatment)]  \n",
       "4                                 [(43, 55, treatment)]  \n",
       "...                                                 ...  \n",
       "7182  [(46, 63, cancer), (73, 80, treatment), (82, 9...  \n",
       "7183  [(1, 5, treatment), (11, 13, cancer), (39, 48,...  \n",
       "7184  [(27, 29, cancer), (157, 171, cancer), (186, 2...  \n",
       "7185  [(40, 51, treatment), (53, 69, treatment), (71...  \n",
       "7186  [(23, 45, chronic_disease), (47, 68, chronic_d...  \n",
       "\n",
       "[7187 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {'classes' : ['allergy_name', 'treatment', 'chronic_disease', 'cancer'],\n",
    "                 'annotations': []}\n",
    "\n",
    "for entities, text in zip(df1['entities'], df1['text']):\n",
    "    temp_dict = {'entities': entities,\n",
    "                 'text' : text}\n",
    "    training_data['annotations'].append(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [(8, 16, 'chronic_disease'), (20, 32, 'treatment')],\n",
       " 'text': 'portal fibrosis by liver biopsy'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "doc_bin = DocBin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 6243.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for training_example  in tqdm(training_data['annotations'][:100]): \n",
    "    text = training_example['text']\n",
    "    labels = training_example['entities']\n",
    "    doc = nlp.make_doc(text) \n",
    "    ents = []\n",
    "    for start, end, label in labels:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    filtered_ents = filter_spans(ents)\n",
    "    doc.ents = filtered_ents \n",
    "    doc_bin.add(doc)\n",
    "\n",
    "\n",
    "model_file_dir = \"../model_file_dir\"\n",
    "\n",
    "if not os.path.exists(model_file_dir):\n",
    "    os.makedirs(model_file_dir)\n",
    "\n",
    "doc_bin.to_disk (\"training_data100.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mx = -1\n",
    "# for x in training_data['annotations']:\n",
    "#     mx = max(mx, len(x['text']))\n",
    "\n",
    "# mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mps.set_per_process_memory_fraction(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0         636.77    789.00    3.20    1.70   26.15    0.03\n",
      "\u001b[38;5;3m⚠ Aborting and saving the final best model. Encountered exception:\n",
      "RuntimeError('MPS backend out of memory (MPS allocated: 5.27 GB, other\n",
      "allocations: 31.05 GB, max allowed: 36.27 GB). Tried to allocate 1024 bytes on\n",
      "private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit\n",
      "for memory allocations (may cause system failure).')\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy/__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/typer/core.py\", line 783, in main\n",
      "    return _main(\n",
      "           ^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/typer/core.py\", line 225, in _main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/click/core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/typer/main.py\", line 683, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy/cli/train.py\", line 54, in train_cli\n",
      "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy/cli/train.py\", line 84, in train\n",
      "    train_nlp(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr)\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy/training/loop.py\", line 135, in train\n",
      "    raise e\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy/training/loop.py\", line 118, in train\n",
      "    for batch, info, is_best_checkpoint in training_step_iterator:\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy/training/loop.py\", line 220, in train_while_improving\n",
      "    nlp.update(\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy/language.py\", line 1193, in update\n",
      "    proc.update(examples, sgd=None, losses=losses, **component_cfg[name])  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy_transformers/pipeline_component.py\", line 294, in update\n",
      "    trf_full, bp_trf_full = self.model.begin_update(docs)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/thinc/model.py\", line 328, in begin_update\n",
      "    return self._func(self, X, is_train=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy_transformers/layers/transformer_model.py\", line 199, in forward\n",
      "    model_output, bp_tensors = transformer(wordpieces, is_train)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/thinc/layers/pytorchwrapper.py\", line 224, in forward\n",
      "    Xtorch, get_dX = convert_inputs(model, X, is_train)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/spacy_transformers/layers/transformer_model.py\", line 227, in _convert_transformer_inputs\n",
      "    \"input_ids\": xp2torch(wps.input_ids, device=hf_device),\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/raunakanand/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/thinc/util.py\", line 407, in xp2torch\n",
      "    torch_tensor = torch_tensor.to(device)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: MPS backend out of memory (MPS allocated: 5.27 GB, other allocations: 31.05 GB, max allowed: 36.27 GB). Tried to allocate 1024 bytes on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy --gpu-id 0\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy --gpu-id 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/IPython/core/magics/script.py:155\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Work_R/interview_problems/.venv/lib/python3.12/site-packages/IPython/core/magics/script.py:315\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy --gpu-id 0\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load('model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HIV Positive"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp_ner(training_data['annotations'][101]['text'])\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV Positive\n",
      "[(1, 4, 'chronic_disease')]\n"
     ]
    }
   ],
   "source": [
    "print(training_data['annotations'][101]['text'])\n",
    "print(training_data['annotations'][101]['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">HIV Positive</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {\"chronic_disease\": \"#F67DE3\", \"MEDICINE\": \"#7DF6D9\", \"MEDICALCONDITION\":\"#FFFFFF\"}\n",
    "options = {\"colors\": colors} \n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True,options= options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
